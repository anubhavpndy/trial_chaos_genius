"""convert query string to json

Revision ID: 0a67e1d30de7
Revises: 27d55d03f753
Create Date: 2022-06-23 16:20:06.478712

"""
import json
import re

import pandas as pd
import sqlalchemy as sa
from alembic import op
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '0a67e1d30de7'
down_revision = '27d55d03f753'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('anomaly_data')

    conn = op.get_bind()
    df = pd.read_sql("SELECT * from anomaly_data_output;", conn)

    def conv_query_str_to_json(string: str):
        if string is None:
            return None
        if string in ("mean", "max", "count","min"):
            return json.dumps({"dq": string})
        pattern = re.compile(r'`(.+?)` == "(.+?)"')
        try:
            return json.dumps(dict(
                pattern.match(s).groups() for s in string.split(" and ")
            ))
        except AttributeError:
            raise ValueError(f"Could not coerce `{string}` into valid JSON.")

    df["series_type"] = df["series_type"].apply(conv_query_str_to_json)

    conn.execute("TRUNCATE TABLE anomaly_data_output;")
    op.drop_column('anomaly_data_output', 'series_type')
    op.add_column(
        'anomaly_data_output',
        sa.Column('series_type', postgresql.JSONB(), autoincrement=False, nullable=True)
    )
    df.to_sql('anomaly_data_output', conn, if_exists='append', index=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###

    conn = op.get_bind()
    df = pd.read_sql("SELECT * from anomaly_data_output;", conn)

    def conv_json_to_query_str(json_dict: dict):
        if json_dict is None:
            return None
        if json_dict.get("dq"):
            return json_dict["dq"]
        return " and ".join([f'`{k}` == "{v}"' for k, v in json_dict.items()])

    df["series_type"] = df["series_type"].apply(conv_json_to_query_str)

    conn.execute("TRUNCATE TABLE anomaly_data_output;")
    op.alter_column(
        'anomaly_data_output', 'series_type',
        existing_type=postgresql.JSONB(),
        type_=sa.VARCHAR(length=500),
        existing_nullable=True
    )
    df.to_sql('anomaly_data_output', conn, if_exists='append', index=False)

    op.create_table(
        'anomaly_data',
        sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column('kpi_id', sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column(
            'anomaly_type', sa.VARCHAR(length=80),
            autoincrement=False, nullable=False
        ),
        sa.Column(
            'base_anomaly_id', sa.INTEGER(),
            autoincrement=False, nullable=True
        ),
        sa.Column(
            'drilldown_dimensions', postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False, nullable=True
        ),
        sa.Column(
            'chart_data', postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False, nullable=True
        ),
        sa.Column('severity_score', sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column('anomaly_timestamp', sa.BIGINT(), autoincrement=False, nullable=True),
        sa.Column(
            'created_at', postgresql.TIMESTAMP(),
            autoincrement=False, nullable=False
        ),
        sa.PrimaryKeyConstraint('id', name='anomaly_data_pkey')
    )
    # ### end Alembic commands ###
